{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10H1TQvdaVAW-1XJ9YbUcFvDZ5OosZlrR","timestamp":1677028870450}],"authorship_tag":"ABX9TyO4+ROnHoN7rvS5+3xfEZGt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"ER76bQe6vFU4"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDaxdr0xkOmX","executionInfo":{"status":"ok","timestamp":1677028981057,"user_tz":360,"elapsed":17785,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}},"outputId":"097fd67b-55c0-406a-d06a-fd675e88586a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pygooglenews\n","  Downloading pygooglenews-0.1.2-py3-none-any.whl (10 kB)\n","Collecting beautifulsoup4<5.0.0,>=4.9.1\n","  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting feedparser<6.0.0,>=5.2.1\n","  Downloading feedparser-5.2.1.zip (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dateparser<0.8.0,>=0.7.6\n","  Downloading dateparser-0.7.6-py2.py3-none-any.whl (362 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.0/362.0 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from pygooglenews) (2.25.1)\n","Collecting soupsieve>1.2\n","  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2.8.2)\n","Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.8/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2022.6.2)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (1.5.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2022.7.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2022.12.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->dateparser<0.8.0,>=0.7.6->pygooglenews) (1.15.0)\n","Building wheels for collected packages: feedparser\n","  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feedparser: filename=feedparser-5.2.1-py3-none-any.whl size=44951 sha256=b00344f2e3a6fa01121f226962ae383893bc4dc8650b58330dcdca687030224b\n","  Stored in directory: /root/.cache/pip/wheels/67/38/07/59c89c3d334e7f1f743898af6d21c15ecb3588ad04af7ddee0\n","Successfully built feedparser\n","Installing collected packages: feedparser, soupsieve, dateparser, beautifulsoup4, pygooglenews\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed beautifulsoup4-4.11.2 dateparser-0.7.6 feedparser-5.2.1 pygooglenews-0.1.2 soupsieve-2.4\n"]}],"source":["!pip install pygooglenews\n","import pandas as pd\n","from pygooglenews import GoogleNews\n","import json\n","import time\n","from datetime import datetime"]},{"cell_type":"markdown","source":["# Mount drive\n","\n","This enables us to save the scraped data to a Gdrive we have access to."],"metadata":{"id":"_cQvoy5DvAXj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40VRzOstuMGZ","executionInfo":{"status":"ok","timestamp":1677029226413,"user_tz":360,"elapsed":16760,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}},"outputId":"1f04cf7e-421b-4af1-c09d-aaccdf82ed89"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/GitHub/MNtrafficER"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLBTA5seuycb","executionInfo":{"status":"ok","timestamp":1677029370184,"user_tz":360,"elapsed":418,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}},"outputId":"6f7bb9d8-cb13-41ed-85b5-3c8922fd583d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub\n"]}]},{"cell_type":"markdown","source":["# Scrape news data"],"metadata":{"id":"lvVKIUp2vSoz"}},{"cell_type":"code","source":["current_dttm = str(datetime.now()).replace('.', '_').replace(':', '-')"],"metadata":{"id":"3ASjGnfo0-Zs","executionInfo":{"status":"ok","timestamp":1677030864035,"user_tz":360,"elapsed":214,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["def get_news(search_term, geo = False):\n","  gn = GoogleNews()\n","\n","  if geo:\n","    top = gn.geo_headlines(search_term)\n","  \n","  else:\n","    top = gn.search(search_term)\n","\n","  entries = top[\"entries\"]\n","\n","  news_df = pd.DataFrame({'search_term': search_term,\n","                          'geo': geo,\n","                          'title': [x['title'] for x in entries],\n","                          'published': [x['published'] for x in entries],\n","                          'link': [x['links'][0]['href'] for x in entries],\n","                          'load_dttm': datetime.now()})\n","  \n","\n","  return news_df\n"],"metadata":{"id":"oerDWRmByP5R","executionInfo":{"status":"ok","timestamp":1677030324164,"user_tz":360,"elapsed":3,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["mpls_news = get_news('Minneapolis', geo = True)\n","\n","mpls_traffic = list(map(get_news, ['Minneapolis crashes', 'Minneapolis traffic', 'Twin Cities accidents', 'Twin Cities car accidents', 'Twin Cities car crashes', 'Twin Cities traffic', 'Twin Cities 212 accidents', \n","                                 'Twin Cities 394 accidents', 'Twin Cities 694 accidents', 'Twin Cities 494 accidents']))\n","\n","mpls_news_df = pd.concat([mpls_news] + mpls_traffic)"],"metadata":{"id":"Ti_e_NM8mCRd","executionInfo":{"status":"ok","timestamp":1677030688501,"user_tz":360,"elapsed":1286,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["mpls_news_df.to_csv(f'MNtrafficER/data/pygooglenews_{current_dttm}.csv ')"],"metadata":{"id":"8tL2EiSk0ueB","executionInfo":{"status":"ok","timestamp":1677030906369,"user_tz":360,"elapsed":195,"user":{"displayName":"Nicole Sullivan","userId":"18031182080523530747"}}},"execution_count":63,"outputs":[]}]}